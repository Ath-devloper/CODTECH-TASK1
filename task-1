import pandas as pd

# Load the dataset
file_path = r'C:\Users\HP\Desktop\6th sem\data.csv'  # Replace with the actual file path
data = pd.read_csv(r'C:\Users\HP\Desktop\6th sem\data.csv.csv')

# Display basic information and first few rows
print("Dataset Info:")
print(data.info())
print("\nFirst 5 rows of the dataset:")
print(data.head())

# Check for missing values
print("Missing values in each column:")
print(data.isnull().sum())

# Drop columns that are completely empty or mostly empty
data = data.drop(['Series_title_4', 'Series_title_5'], axis=1)

# Fill missing numerical values with the column mean
data['Data_value'] = data['Data_value'].fillna(data['Data_value'].mean())

# For other columns with missing values, drop rows
data = data.dropna()

# Check the cleaned data
print("\nCleaned dataset info:")
print(data.info())

from sklearn.preprocessing import LabelEncoder

# Encode categorical columns
categorical_columns = data.select_dtypes(include=['object']).columns

for column in categorical_columns:
    print(f"Encoding {column}...")
    encoder = LabelEncoder()
    data[column] = encoder.fit_transform(data[column])

# Check the transformed data
print("\nTransformed dataset (with encoded categorical columns):")
print(data.head())

from sklearn.model_selection import train_test_split

# Define the target column
target_column = 'STATUS'  # Replace with your target column name
X = data.drop(target_column, axis=1)  # Features
y = data[target_column]              # Target

# Split the data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print("Training and testing sets created successfully!")
print(f"Training data shape: {X_train.shape}")
print(f"Testing data shape: {X_test.shape}")

import os
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder

def data_pipeline(file_path, target_column, output_folder):
    # Ensure the output folder exists
    if not os.path.exists(output_folder):
        print(f"Creating output folder at: {output_folder}")
        os.makedirs(output_folder)
    else:
        print(f"Output folder already exists at: {output_folder}")

    # Load the dataset
    print("Loading dataset...")
    data = pd.read_csv(file_path)

    # Drop empty or irrelevant columns (if they exist)
    print("Dropping irrelevant columns...")
    data = data.drop(['Series_title_4', 'Series_title_5'], axis=1, errors='ignore')

    # Handle missing values
    print("Handling missing values...")
    data['Data_value'] = data['Data_value'].fillna(data['Data_value'].mean())
    data = data.dropna()

    # Encode categorical columns
    print("Encoding categorical columns...")
    categorical_columns = data.select_dtypes(include=['object']).columns
    for column in categorical_columns:
        encoder = LabelEncoder()
        data[column] = encoder.fit_transform(data[column])

    # Split the data into training and testing sets
    print("Splitting data into training and testing sets...")
    X = data.drop(target_column, axis=1)
    y = data[target_column]
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # Save the processed data to CSV files
    print("Saving processed data...")
    X_train.to_csv(os.path.join(output_folder, "train_data.csv"), index=False)
    X_test.to_csv(os.path.join(output_folder, "test_data.csv"), index=False)
    y_train.to_csv(os.path.join(output_folder, "train_labels.csv"), index=False)
    y_test.to_csv(os.path.join(output_folder, "test_labels.csv"), index=False)

    print("Data pipeline executed successfully! Processed files saved in the output folder.")

# Define input parameters
file_path = r'C:\Users\HP\Desktop\6th sem\data.csv.csv'  # Input file path
output_folder = r'C:\Users\HP\Desktop\6th sem\output'   # Output folder path
target_column = 'STATUS'                                # Target column name

# Run the pipeline
data_pipeline(file_path, target_column, output_folder)
